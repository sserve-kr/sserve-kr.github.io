---
title: 히토미 태그 크롤러 만들기
categories:
- 프로그래밍
- 파이썬
- 웹 크롤링
excerpt: Requests와 Beautifulsoup4 라이브러리를 활용한 히토미 태그 크롤링 스크립트 짜기
feature_text: |
  # 후방주의
feature_image: "https://www.sserve.me/assets/postassets/"
---

# Hitomi Tag Crawling
히토미에서 태그를 긁어 봅시다.  

## 필수 라이브러리 설치
먼저, 웹 크롤링에 필수적으로 들어가는 `Requests` 라이브러리와 `Beautifulsoup4` 라이브러리를 설치하고 시작합니다.  
`pip install requests`  
`pip install beautifulsoup4`  

## 웹에서 데이터 찾기
히토미의 태그 데이터는 **A-Z 알파벳 순**으로 깔끔하게 정리되어 있습니다.  
URL 패턴은 `https://hitomi.la/alltags-[a-z].html` 입니다.  

위 URL의 Network를 살펴보면, 따로 데이터를 주고받는 것으로 보이지 않습니다.  
따라서 HTML 데이터를 받은 뒤, Beautifulsoup4로 요리해 주겠습니다.  

HTML 데이터를 살펴봅시다.  
태그는 리스트로 감싸져 있습니다. 리스트의 `class` 값은 `posts` 구요.  
이 리스트가 여러개로 나뉘어 여러 줄을 이루고 있군요.  

그렇다면 `posts`라는 `class` 값을 가진 태그를 Beautifulsoup4를 이용해 가져오고,  
그 안의 자식 태그들 중에서 li 태그를 리스트로 가져와 데이터로 만들면 될 것 같습니다.

## 구현하기
이제 찾을 데이터는 찾았으니, 구현을 시도해봅시다.  

### 데이터를 저장할 방식 
먼저, `sqlite3` 라는 기본 라이브러리를 활용해 DB 파일을 만들고, Tags 테이블을 만들어 태그를 저장할 것입니다.  
따라서 그에 맞는 코드를 작성해 주겠습니다. (실행은 하지 않습니다.)  

```python
import sqlite3
from datetime import datetime

nowtime = datetime.now()
db = sqlite3.connect(f'Tags_[{nowtime.year}-{nowtime.month}-{nowtime.day}].db')
cursor = db.cursor()

table_cr = '''
CREATE TABLE IF NOT EXISTS Tags (
    Prefix varchar(255),
    Tag varchar(255),
    PostLength int
)
'''

cursor.execute(table_cr)
db.commit()
```

### HTML 데이터 가져오기
이제 HTML 데이터를 가져와야 합니다.  
데이터를 가져올 때 for 반복문을 이용해 알파벳을 숫자->문자로 변환시켜주면 됩니다.  
이를 위해 `ord()` 함수와 `chr()` 함수를 사용합니다.  

```python
print(ord('a'))
print(chr(ord('a')))
print(ord('z'))
print(chr(ord('z')))
```
```
97
a
122
z
```
이처럼 ord는 문자를 숫자로, chr은 숫자를 문자로 바꿔줍니다. (정확하게는 숫자가 아닌 아스키 코드입니다.)  
이제 스크립트에 추가해줍니다.
```python
import sqlite3
from datetime import datetime
import requests  # 추가

nowtime = datetime.now()
db = sqlite3.connect(f'Tags_[{nowtime.year}-{nowtime.month}-{nowtime.day}].db')
cursor = db.cursor()

table_cr = '''
CREATE TABLE IF NOT EXISTS Tags (
    Prefix varchar(255),
    Tag varchar(255),
    PostLength int
)
'''

cursor.execute(table_cr)
db.commit()

for alphabet_num in range(ord('a'), ord('z')+1):  # 추가
    api_url = f'https://hitomi.la/alltags-{chr(alphabet_num)}.html'
    print(f'SENT GET TO {api_url}')
    response = requests.get(api_url)
```

### 태그만 리스트로 만들기
이제 태그 데이터가 담긴 HTML 데이터가 주어졌으므로,  
데이터를 찾는 부분에서 적어둔 대로 Beautifulsoup4를 이용해 요리합시다.  

먼저 BeautifulSoup 객체를 만들고,  
```python
soup = BeautifulSoup(response.content, 'html.parser')
```

`class`가 `posts`인 ul 태그를 가져옵시다.  
```python
posts = soup.find_all('ul', {'class': 'posts'})
```

그 리스트의 자식들 중에서 li 태그를 가져옵니다.
```python
tags = posts.find_all('li', recursive=False)
```

이제 이것을 스크립트에 알맞게 추가해봅시다.  
```python
import sqlite3
from datetime import datetime
import requests
from bs4 import BeauifulSoup  # 추가

nowtime = datetime.now()
db = sqlite3.connect(f'Tags_[{nowtime.year}-{nowtime.month}-{nowtime.day}].db')
cursor = db.cursor()

table_cr = '''
CREATE TABLE IF NOT EXISTS Tags (
    Prefix varchar(255),
    Tag varchar(255),
    PostLength int
)
'''

cursor.execute(table_cr)
db.commit()

for alphabet_num in range(ord('a'), ord('z')+1):
    api_url = f'https://hitomi.la/alltags-{chr(alphabet_num)}.html'
    print(f'SENT GET TO {api_url}')
    response = requests.get(api_url)
    soup = BeautifulSoup(response.content, 'html.parser')  # 추가
    for posts in soup.find_all('ul', {'class': 'posts'}):
        for item in posts.find_all('li', recursive=False):
            tag = item.get_text()
```

### 태그 텍스트 요리
이제 태그 텍스트까지 가져왔습니다.  
남은 단계는 태그 텍스트를 분리해서 알맞게 조정한 후, 데이터베이스에 넣는 것이죠.  

데이터베이스의 테이블에는 3가지의 column이 있습니다.  
`Prefix`, `Tag`, `PostLength`죠.  

`Prefix`는 흔히 히토미에서 검색할 때 입력하는 **female**, **male**, **tag** 등입니다.  
간단하게 하면 그냥 **:** 앞에 오는 단어라고 할 수 있습니다.  
HTML 데이터에서는 특별한 기호(♀, ♂)로 표시됩니다.  
**♂ 기호**는 남성 전용 태그,  
**♀ 기호**는 여성 전용 태그를 나타내고,  
**기호가 없을 경우**는 성별을 따질 수 없거나 공통적인 부분인 태그입니다 (tag:...)  

`Tag`는 태그 본문입니다.  
마찬가지로 **:** 뒤에 오는 단어라고 할 수 있습니다.  

`PostLength`는 작품 수입니다.  
히토미에서 태그로 검색하면 흔히 나오는 작품 수가, HTML 데이터에서는 맨 오른쪽에 있는 `(숫자)` 형식으로 나타나 있습니다.  

따라서 이런 방식으로 `prefix`, `tag`, `postlength` 값을 구할 수 있습니다.  
```python
tag = item.get_text()
tag = tag.replace(" ", "_")
tag_num = tag[tag.index('(')+1:tag.index(')')]
tag = tag[:tag.index('(')]
prefix = "tag"
if FEMALE in tag:
    prefix = "female"
    tag = tag[:tag.index(FEMALE)]
elif MALE in tag:
    prefix = "male"
    tag = tag[:tag.index(MALE)]
if tag[-1] == '_':
    tag = tag[:-1]
```

이것을 스크립트에 추가하겠습니다.  

```python
import sqlite3
from datetime import datetime
import requests
from bs4 import BeauifulSoup  # 추가

nowtime = datetime.now()
db = sqlite3.connect(f'Tags_[{nowtime.year}-{nowtime.month}-{nowtime.day}].db')
cursor = db.cursor()

table_cr = '''
CREATE TABLE IF NOT EXISTS Tags (
    Prefix varchar(255),
    Tag varchar(255),
    PostLength int
)
'''

cursor.execute(table_cr)
db.commit()

FEMALE = '♀'
MALE = '♂'

for alphabet_num in range(ord('a'), ord('z')+1):
    api_url = f'https://hitomi.la/alltags-{chr(alphabet_num)}.html'
    print(f'SENT GET TO {api_url}')
    response = requests.get(api_url)
    soup = BeautifulSoup(response.content, 'html.parser')  # 추가
    for posts in soup.find_all('ul', {'class': 'posts'}):
        for item in posts.find_all('li', recursive=False):
            tag = item.get_text()
            tag = tag.replace(" ", "_")
            tag_num = tag[tag.index('(')+1:tag.index(')')]
            tag = tag[:tag.index('(')]
            prefix = "tag"
            if FEMALE in tag:
                prefix = "female"
                tag = tag[:tag.index(FEMALE)]
            elif MALE in tag:
                prefix = "male"
                tag = tag[:tag.index(MALE)]
            if tag[-1] == '_':
                tag = tag[:-1]
            print(f'("{prefix}", "{tag}", {tag_num})')
```

### 데이터 저장
이제 구한 데이터들을 데이터베이스에 넣겠습니다.  
이 단계는 어렵지 않습니다.

```python
cursor.execute(f'INSERT INTO Tags VALUES ("{prefix}", "{tag}", {tag_num})')
```
이 코드를 태그 하나를 구하는 코드 뒤에 추가하고 커밋하면 됩니다.  
다만, 커밋은 혹시 도중에 오류가 날 수 있으니 데이터가 꼬이지 않도록 맨 마지막에 해주도록 합시다.  
이상을 추가하면 최종 결과물은 다음과 같습니다.  

```python
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import sqlite3

nowtime = datetime.now()
db = sqlite3.connect(f'Tags_[{nowtime.year}-{nowtime.month}-{nowtime.day}].db')
cursor = db.cursor()

table_cr = '''
CREATE TABLE IF NOT EXISTS Tags (
    Prefix varchar(255),
    Tag varchar(255),
    PostLength int
)
'''

cursor.execute(table_cr)
db.commit()

FEMALE = '♀'
MALE = '♂'

for alphabet_num in range(ord('a'), ord('z')+1):
    api_url = f'https://hitomi.la/alltags-{chr(alphabet_num)}.html'
    print(f'SENT GET TO {api_url}')
    response = requests.get(api_url)
    soup = BeautifulSoup(response.content, 'html.parser')
    for posts in soup.find_all('ul', {'class': 'posts'}):
        for item in posts.find_all('li', recursive=False):
            tag = item.get_text()
            tag = tag.replace(" ", "_")
            tag_num = tag[tag.index('(')+1:tag.index(')')]
            tag = tag[:tag.index('(')]
            prefix = "tag"
            if FEMALE in tag:
                prefix = "female"
                tag = tag[:tag.index(FEMALE)]
            elif MALE in tag:
                prefix = "male"
                tag = tag[:tag.index(MALE)]
            if tag[-1] == '_':
                tag = tag[:-1]
            print(f'("{prefix}", "{tag}", {tag_num})')
            cursor.execute(f'INSERT INTO Tags VALUES ("{prefix}", "{tag}", {tag_num})')
db.commit()
```

이 글은 제가 한 번 스크립트를 만들고 난 뒤 쓴 글입니다.  
이 글에 쓰인 스크립트는 [이 레포지토리](https://github.com/sserve-kr/hitomitagcrawler)에서 볼 수 있습니다.
